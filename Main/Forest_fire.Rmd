---
title: "Forest Fires - Gruppo Capri"
author: "Andrei Petrisor 1085993, Antonio Radu 1085992, Lorenzo Medici 1085852, Andrea Rusconi 1086646"
date: "15-01-2024"
output:
  
  pdf_document:
    
    toc: true
    number_sections: true
    fig_width: 7
    fig_height: 6
    fig_caption: true
  fontsize: 11pt
  geometry: margin=1in
  html_document:
    theme: cerulean
    toc: yes
    toc_float: yes
  word_document:
    toc: yes
editor_options:
  markdown:
    wrap: 72
    title: "test"
---
```{r, include=FALSE}
#mi serve per creare pdf
options(tinytex.verbose = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css echo=F, message=F}
.columns{display:flex;}
h1{color:#1e90ff;}

h2{color:blue;}

```
\newpage

# Dataset

Questo dataset è pubblico e a disposizione per la ricerca. I dettagli
sul dataset possono essere trovati in Cortez e Morais (2007). Il dataset
è composto dalle seguenti variabili:

1.  Coordinata spaziale dell'asse X all'interno della mappa del parco
    Montesinho: da 1 a 9
2.  Y coordinata spaziale dell'asse y all'interno della mappa del parco
    Montesinho: da 2 a 9
3.  mese dell'anno: da "jan" a "dec"
4.  giorno della settimana: da "mon" a "sun"
5.  Indice FFMC dal sistema FWI: da 18,7 a 96,20
6.  Indice DMC dal sistema FWI: da 1,1 a 291,3
7.  Indice DC dal sistema FWI: da 7,9 a 860,6
8.  Indice ISI del sistema FWI: da 0,0 a 56,10
9.  temperatura temporanea in gradi Celsius: da 2,2 a 33,30
10. Umidità relativa RH in %: da 15,0 a 100
11. velocità del vento in km/h: da 0,40 a 9,40
12. pioggia in mm/m2: da 0,0 a 6,4
13. area della superficie bruciata della foresta (in ettari): da 0,00 a
    1090,84.

Il Forest Fire Weather Index (FWI) è il sistema canadese per la classificazione 
del pericolo di incendio e comprende sei componenti:
Indice di umidità del combustibile (FFMC), indice di umidità (DMC), 
indice di siccità (DC), indice di spread iniziale (ISI), indice di accumulo (BUI) e FWI
    
## Obiettivo

In questo dataset siamo interessati a modellare l'area bruciata della foresta come funzione delle altre variabili. Siamo in particolare interessati a rispondere alla domanda: "Concentrandosi sul mese di agosto, come si può spiegare l'area bruciata in funzione delle altre variabili?".


Cortez P. e Morais A. "Un approccio di data mining per prevedere gli
incendi boschivi utilizzando dati meteorologici." In J. Neves, MF Santos
e J. Machado Eds., "Nuove tendenze nell'intelligenza artificiale", Atti
della 13a EPIA 2007 Conferenza portoghese sull'intelligenza artificiale,
dicembre, Guimaraes, Por- tugal, pp. 512-523, 2007. APPIA, ISBN-13
978-989-95618-0-9. 18-0-9. Disponibile a:
<http://www3.dsi.uminho.pt/pcortez/fires.pdf>

Il dataset è composto dalle seguenti rilevazioni:
```{r, echo=F, message=F}
# Carichiamo il dataset in formato .csv
# Importante: bisogna specificare la directory dove il file è salvato.

forest <- read.csv("C:/Forest-Fires/Dataset&Documentation/forestfires.csv")
# Vediamo il nome delle variabili:

# Il comando 'summary' ci consente di vedere un riassunto delle variabili del dataset (min, max, etc.)
#summary(forest)

# Vediamo se ci sono valori mancanti nel dataset:
#sum(is.na(forest))

# Consiglio di rimuovere X e Y (le coordinate) dal set di variabili dipendenti in uso:
forest <- forest[,-c(1:2)]
#summary(forest)
# Vediamo le prime 6 osservazioni che compongono il dataset:
#head(forest)

# Dato che month e day vengono considerate come character e non factor le trasformiamo:
Months <- factor(forest$month, levels = c('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dic'))
Days <- factor(forest$day, levels = c('mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'))
forest$month <- as.factor(forest$month)
forest$day <- as.factor(forest$day)
# Vediamo un pochino meglio il dataset ora:
# summary(forest)
# table(forest$month)
# table(forest$day)

table(Months, Days)
```

## Istogrammi area bruciata

```{r, figures-side1, fig.show="hold", out.width="50%",echo=F, message=F}
# La variabile risposta è "area", studiamola più nello specifico:
hist(forest$area, col = "red", breaks=15, ylab = "Frequency", xlab = "Hectars", main = "Burned area in Hectars")
mtext("Fig.1", side=4, line=1)
# Histogramma di prima considerato tramite il logaritmo
hist((log(forest$area)), col = "red", breaks=15, ylab = "Frequency", xlab = "Hectars", main = "Ln transform")
mtext("Fig.2", side=4, line=1)
```
Possiamo vedere dall'istogramma(Fig.1) come i dati sono assimetrici verso lo zero, di conseguenza valutiamo i dati
facendo la trasformata grazie al logaritmo, cosifacendo otteniamo un grafico più simile ad una normale.

```{r}
summary(forest$area)
```
Facendo il summary otteniamo i valori di: min, max, media, mediana, possiamo considerare i nostri dati molto vicini allo zero.

```{r, echo=F, message=F}
sum(forest$area==0)/length(forest$area) # circa 48% sono 0
```
Si evidenzia che il dataset ha il 48% dei valori che valgono 0.

## Grafici densità area bruciata

```{r, figures-side3, fig.show="hold", out.width="50%", echo=F, message=F}
# Vediamo meglio il grafico della densità della variabile:
plot(density(forest$area), col="blue",main = "Densità area")
# E' molto asimmetrica verso lo 0, proviamo a farne una trasformata:
plot(density(log(forest$area)), col="blue",main = "Ln Densità area")
```
\newpage

Sembra esserci anche una forte distorsione rispetto ai residui che non sono normalmente distribuiti. Ciò sembra essere dovuto al gran numero di 0 nel database. Quando questi 0 vengono rimossi, possiamo vedere che i residui diventano più normalmente distribuiti.

```{r, echo=F, message=F}
# Dobbiamo però tener conto del numero di 0 presenti: log(0) = -Inf, quindi
forest$area <- log(forest$area+1)
summary(forest$area)
```
come possiamo vedere la mediana e la media sono diminuite.

```{r, figures-side4, fig.show="hold", out.width="50%", echo=F, message=F}
# Correlazione tra variabili (quantitative):
# OPZIONALE (non dà punti extra):
# Siccome i mesi e giorni sono variabili qualitative con più livelli, R automaticamente splitta in livelli le variabili usando il modello lineare o lineare generalizzato.
# Proviamo a farlo noi con una funzione implementata in R:
# forest <- fastDummies::dummy_cols(forest, remove_first_dummy = TRUE)[-c(1,2)]
# summary(forest)
# Visualizzazione delle variabili:
boxplot(forest[,-c(1,2)], main="variables", col=rainbow(9), line = "box")
mtext("Fig.1", side=4, line=1)
# c'è differenza nei giorni?
boxplot(forest$area ~ Days, xlab = "day", ylab = "area", main="week", col=rainbow(7))
mtext("Fig.2", side=4, line=1)
# cosa succede a Dicembre?
boxplot(forest$area ~ Months, xlab = "mounth", ylab = "area", main="year", col=rainbow(12))
mtext("Fig.3", side=4, line=1)

library(corrplot)
M <- cor(as.matrix(forest[,-c(1,2)])) # correlation matrix
corrplot(M, method = 'number')
mtext("Fig.4", side=4, line=1)#side  1 = sotto, 2 = sinistra, 3 = sopra, 4 = destra.
#line da 1,-1,-2 ecc si sposta verso il centro
```
-Come possiamo vedere da questo correlation plot(fig.4) le variabili che sono correlate positivamente di più
sono: DC con DMC, ISI e FFMC, temp e DC. Le variabili correlate negativamente di più sono, invece: RH e temp.

-Dal box plot delle variabili(fig.1) possiamo determinare che le mediane di quasi tutte le variabili sono più o meno simili quindi ci sono poche differenze,inoltre possiamo notare come in tutte le variabili ci siano degli outliers sia al minimo che al massimo. La variabile DMC, invece, presenta dei baffi più lunghi il che implica che tale variabile ha valori più incoerenti rispetto alle altre, la mediana è lontana da tutte le altre ed è spostata molto verso il terzo quartile.

-Dal box plot dei giorni della settimana(fig.2) possiamo vedere come le mediane siano simili tra di loro, come anche i baffi, questo dimostra come i giorni della settimana abbiano tutti valori coerenti tra di loro.

-Dal box plot dei mesi dell'anno(fig.3) notiamo come il mese di dicembre e quello di maggio siano quelli più incoerenti rispetto agli altri mesi. Il mese di agosto presenta molti più outliers rispetto agli altri mesi.

# Testing

Per la fase di testing prendiamo in considerazione solamente il mese di agosto, per poter spiegare come varia l'area bruciata in relazione alle altre variabili. Dividiamo la fase di Testing in: train e test, con il train al 70% e il test al 30%.
Questo è il nostro nuovo dataset:

```{r, echo=F, message=F}
forest_subset <- forest[which(forest$month=="aug"),]
forest_subset <- forest_subset[,-c(1)]#elimino colonna month dal dataset
#summary(forest_subset)
```

Proviamo a fare un modello lineare con i dati del mese di agosto. Le variabili che secondo noi ha piu senso considerare nel modello sono: rain ,RH ,temp, FFMC, e DMC. RH-FFMC-DMC sono degli indici che tengono conto dell'umidità. Nessuno di questi parametri agisce in modo diretto sullo sviluppo dell’incendio, ma sono tutti fattori predisponenti, perciò consideriamo rilevante studiare come influenzano l'area incendiata.


```{r,echo=F, message=F}
# Optional:
#forest <- fastDummies::dummy_cols(forest, remove_first_dummy = TRUE)[-c(1,2)]
# Regole classiche sono 70% training e 30% test (o 80-20 a vostra scelta)
set.seed(125) # il seme serve per riprodurre le analisi (reproducibilità del codice)
sample <- sample(c(TRUE, FALSE), nrow(forest_subset ), replace=TRUE, prob=c(0.7,0.3))
train  <- forest_subset [sample, ]
test   <- forest_subset [!sample, ]

# Modello con una sola variabile:
# model = lm(area ~ rain, data = train)

#summary(model)

# Modello con poche:
model1 = lm(area ~ rain+RH+temp+FFMC+DMC, data = train)
summary(model1)

```

Come possiamo vedere il nostro modello non performa benissimo, con un 4% come r^2 il modello ha un grande margine di errore. Tra le varie covariate scelte notiamo come la temperatura abbia il valore piu grande, quindi,  all'aumentare unitario dell'area, la temperatura media aumenta di 0.08. Proviamo a vedere se ci sono degli Outliers(valori estremi) nel modello.

\newpage

```{r,figures-side5, fig.show="hold", out.width="50%", echo=F, message=F}

# Diagnostic plot del modello:
par(mfrow=c(2,2)) # finestra grafica 2x2
plot(model1)
par(mfrow=c(1,1)) # riportiamo ai valori di default

mtext("Fig.1", side=4, line=1)#side  1 = sotto, 2 = sinistra, 3 = sopra, 4 = destra.

# Rimuovere osservazioni basandoci sui valori delle variabili:
# train=train[!(train$temp>300),]
# rimuovere outlier:
# install.packages("olsrr")
library(olsrr)
ols_plot_resid_lev(model1)

#mtext("Fig.2", side=4, line=1)#side  1 = sotto, 2 = sinistra, 3 = sopra, 4 = destra.
```

Possiamo vedere come nel grafici (Fig.1), un numero considerevole di osservazioni non segue l'andamento desiderato, poniamo maggiore attenzione sul grafico Q-Q Res. dove possiamo vedere che i vari valori alle code tendono a spostarsi di molto, l'andamento non tende per niente alla normale. Per quanto riguarda il grafico a destra possiamo notare come alcune rilevazioni siano parecchio "lontane" rispetto alle altre, poniamo attenzione soprattuto a quelle che sono Outlier&Leverage e le rimuoviamo. 


```{r,echo=F, message=F}
# Removing observations guardando numero dell'osservazione:
#rownames(train) per vedere il la posizione dei valori di train
train = train[-c(76,78,47,3,114,45),]#attenzione i numeri si riferiscono alla posizione dell'array degli outlier
#416 421 228 13 500 212
#76  78  47  3  114 45
# Modello 1 senza outlier:
model2 = lm(area ~ rain+RH+temp+FFMC+DMC, data = train)
summary(model2)
# Modello con variabili scelte da noi (scelte casualmente al momento):
model3 = lm(area ~ ., data = train)
#summary(model3)

# Test ANOVA
#anova(model3)

```

Il modello presenta un leggero miglioramento, l'r^2 aumenta del 7% rendendo il modello un minimo piu preciso. La covariata piu significativa è la temperatura, quindi all'aumentare unitario dell'area, la temperatura media aumenta di 0.12. I coefficienti associati alle variabili rain, FFMC, DMC non sono significativi, quindi supponiamo non influiscano sull'area. Passando da non avere la rain ad averla, a parità di temperatura, l'area diminuisce di 0.87.

## Confronto tra modelli

Per valutare quale dei 3 modelli (1o modello con variabili scelte da noi, il  2o modello  è uguale al primo, ma senza outliers, il 3o modello presenta tutte le variabili) sia meglio li mettiamo a confronto tramite la tecnica AIC(Akaike information criterion). Consiste in un metodo per la valutazione e il confronto tra modelli statistici. Fornisce una misura della qualità della stima di un modello statistico tenendo conto sia della bontà di adattamento che della complessità del modello. La regola è quella di preferire i modelli con l’AIC più basso.

```{r, echo=F,message = F}
# Create vector with values
a = c(AIC(model3), BIC(model3), AIC(model2), BIC(model2), AIC(model1), BIC(model1))

# Akaike Information Criterion (AIC) estimates the in-sample prediction error and indicates the relative quality of statistical models for a given dataset (it is only useful to compare models based on the same data). Bayesian Information Criterion (BIC) is a penalized-likelihood criterion derived from Bayesian probability. It is closely related to AIC. Generally, lower values of BIC and AIC are preferred.

# Create vector with nforest
b = c("AIC lm 3", "BIC lm 3", "AIC lm 2", "BIC lm 2", "AIC lm 1", "BIC lm 1")

# Link the values with nforest
names(a) = b
print(a)
```
I risultati ci mostrano come il modello 2 abbia l'AIC piu basso, useremo questo modello per fare le previsioni.

## Previsioni puntuale

Per STIMA PUNTUALE DEI PARAMETRI s’intende l’insieme dei metodi inferenziali che permettono di attribuire un valore ad un parametro della popolazione, utilizzando i dati di un campione casuale osservato (x1, x2,…,xn) ed elaborandoli.Per valutare la bontà di uno stimatore è necessario considerare le stime ottenute ripetendo un grande numero di volte il processo impiegato per eseguire una stima.  

```{r, echo=F,message = F}
#use lasso regression model to predict response value
new = test
previsioni_mod2 = predict(model2, newdata = new)#previsione puntuale

#find SST and SSE
sst <- sum((test$area - mean(test$area))^2)
sse <- sum((previsioni_mod2 - test$area)^2)

# Root Mean Squared Error: è una misura dell'errore che compiamo
sqrt(mean((test$area - previsioni_mod2)^2))#--

# intervallo di previsione
# predict(model3,new,interval="predict", level=0.95)#intervallo di previsione
```

## LASSO regression

La tecnica LASSO(least absolute shrinkage and selection operator) è un metodo di analisi della regressione che esegue sia la selezione delle variabili sia la regolarizzazione per migliorare l'accuratezza della previsione e l'interpretabilità del modello statistico risultante. Il metodo lasso presuppone che i coefficienti del modello lineare siano sparsi, ossia che pochi di essi siano non nulli. 

```{r,figures-side7, fig.show="hold", out.width="50%", echo=F, message = F}
#penalizza le covariate,avra una parte classica piu un errore
# install.packages("glmnet") # se non è già stato installato
library(glmnet) 

#define response variable
y <- train$area

#define matrix of predictor variables (uso solo poche variabili ma potete farlo con tutte da togliere però la risposta area)
x <- data.matrix(train[, c("RH","rain","temp","FFMC","DMC")])

#perform k-fold cross-validation to find optimal lambda value, la cross-validation è un ottimo modo per non overfittare e trovare il miglior modello
cv_model <- cv.glmnet(x, y, alpha = 1)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda#miglior lambda per penalizzare

#produce plot of test MSE by lambda value
plot(cv_model) 

# Fittiamo il modello con il best lambda (penalizzazione)

best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
```

Il grafico dovrebbe assomigliare ad una curva esponenziale, nel nostro caso il mean-squared error assomiglia ad una retta.

## Previsioni con Lasso
```{r, message = F}
#use lasso regression model to predict response value
new = data.matrix(test[,c("RH","rain","temp","FFMC","DMC")])
previsioni = predict(best_model, s = best_lambda, newx = new)

# Root Mean Squared Error (RMSE): è una misura dell'errore che compiamo
sqrt(mean((test$area - previsioni)^2))#errore minimo

```

Come possiamo vedere la previsione con la Lasso è migliore rispetto alla previsone puntuale, decidiamo quindi di usare la Lasso regression per prevedere i dati. 

# Conclusioni

Concentrandosi sul mese di agosto, spiegare l'area bruciata in funzionde delle altre variabili risulta non facile visto la poca quantità di dati a disposizione. Poiché il valore r2 del modello è molto basso, probabilmente significa che i predittori avranno un errore significativo e potrebbero non essere affidabili.
