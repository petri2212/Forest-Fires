---
title: "Forest Fires - Gruppo Capri"
author: "Andrei Petrisor 1085993, Antonio Radu 1085992, Lorenzo Medici 1085852, Andrea Rusconi 1086646"
date: "15-01-2024"
output:
  
  html_document:
    theme: cerulean
    toc: yes
    toc_float: yes
  fontsize: 11pt
  geometry: margin=1in
  pdf_document:
    
    toc: true
    number_sections: true
    fig_width: 7
    fig_height: 6
    fig_caption: true
  word_document:
    toc: yes
editor_options:
  markdown:
    wrap: 72
    title: "test"
---
```{r, include=FALSE}
#mi serve per creare pdf
options(tinytex.verbose = TRUE)

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css echo=F, message=F}
.columns{display:flex;}
h1{color:#1e90ff;}

h2{color:blue;}

```

\newpage

# Dataset

Questo dataset (A Data Mining Approach to Predict Forest Fires
using Meteorological Data)[^90] è pubblico e a disposizione per la ricerca. I dettagli
sul dataset possono essere trovati in Cortez e Morais (2007). Il dataset
è composto dalle seguenti variabili:

1.  Coordinata spaziale dell'asse X all'interno della mappa del parco
    Montesinho: da 1 a 9
2.  Y coordinata spaziale dell'asse y all'interno della mappa del parco
    Montesinho: da 2 a 9
3.  mese dell'anno: da "jan" a "dec"
4.  giorno della settimana: da "mon" a "sun"
5.  Indice FFMC dal sistema FWI: da 18,7 a 96,20
6.  Indice DMC dal sistema FWI: da 1,1 a 291,3
7.  Indice DC dal sistema FWI: da 7,9 a 860,6
8.  Indice ISI del sistema FWI: da 0,0 a 56,10
9.  temperatura temporanea in gradi Celsius: da 2,2 a 33,30
10. Umidità relativa RH in %: da 15,0 a 100
11. velocità del vento in km/h: da 0,40 a 9,40
12. pioggia in mm/m2: da 0,0 a 6,4
13. area della superficie bruciata della foresta (in ettari): da 0,00 a
    1090,84.

Il Forest Fire Weather Index (FWI) è il sistema canadese per la classificazione 
del pericolo di incendio e comprende sei componenti:
Indice di umidità del combustibile (FFMC), indice di umidità (DMC), 
indice di siccità (DC), indice di dispersione iniziale (ISI) nel nostro caso indica la velocità della diffusione del fuoco, indice di accumulo (BUI) e FWI
    
Il dataset è composto dalle seguenti rilevazioni:
```{r, echo=F, message=F}
# Carichiamo il dataset in formato .csv
# Importante: bisogna specificare la directory dove il file è salvato.


forest <- read.csv("C:/Users/radut/Documents/Forest-Fires/Dataset&Documentation/forestfires.csv")

# Vediamo il nome delle variabili:

# Il comando 'summary' ci consente di vedere un riassunto delle variabili del dataset (min, max, etc.)
#summary(forest)

# Vediamo se ci sono valori mancanti nel dataset:
#sum(is.na(forest))

# Consiglio di rimuovere X e Y (le coordinate) dal set di variabili dipendenti in uso:
forest <- forest[,-c(1:2)]
#summary(forest)
# Vediamo le prime 6 osservazioni che compongono il dataset:
#head(forest)

# Dato che month e day vengono considerate come character e non factor le trasformiamo:
Months <- factor(forest$month, levels = c('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dic'))
Days <- factor(forest$day, levels = c('mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'))
forest$month <- as.factor(forest$month)
forest$day <- as.factor(forest$day)
# Vediamo un pochino meglio il dataset ora:
# summary(forest)
# table(forest$month)
# table(forest$day)

table(Months, Days)
```

La tabella rappresenta il numero di osservazioni per mese(righe) e per giorno(colonne) della settimana.

[^90]:Per ulteriori informazioni sul dataset visitare il link: <http://www3.dsi.uminho.pt/pcortez/fires.pdf>


\newpage

## Istogrammi area bruciata

```{r, figures-side1, fig.show="hold", out.width="50%",echo=F, message=F}
# La variabile risposta è "area", studiamola più nello specifico:
hist(forest$area, col = "red", breaks=15, ylab = "Frequency", xlab = "Hectars", main = "Burned area in Hectars")
mtext("Fig.1", side=4, line=1)
# Histogramma di prima considerato tramite il logaritmo
hist((log(forest$area)), col = "red", breaks=15, ylab = "Frequency", xlab = "Hectars", main = "Ln transform")
mtext("Fig.2", side=4, line=1)
```
Possiamo vedere come l'istogramma(Fig.1) presenti una asimmetria positiva(obliqua a destra) , di conseguenza log-trasformiamo i dati, cosifacendo otteniamo un grafico più simile ad una normale.

```{r}
summary(forest$area)
```
Facendo il summary dei dati originali(non quelli log-trasformati) otteniamo i valori di: min, max, media, mediana, possiamo considerare i nostri dati molto vicini allo zero.

```{r, echo=F, message=F}
sum(forest$area==0)/length(forest$area) # circa 48% sono 0
```
Si evidenzia che il dataset ha circa il 48% dei valori che valgono 0.

## Grafici densità area bruciata

```{r, figures-side3, fig.show="hold", out.width="50%", echo=F, message=F}
# Vediamo meglio il grafico della densità della variabile:
plot(density(forest$area), col="blue",main = "Densità area")
# E' molto asimmetrica verso lo 0, proviamo a farne una trasformata:
plot(density(log(forest$area)), col="blue",main = "Ln Densità area")
```
\newpage

Sembra esserci anche una forte distorsione rispetto ai residui che non sono normalmente distribuiti. Ciò sembra essere dovuto al gran numero di 0 nel database. 

```{r, echo=F, message=F,warning=F}
library(PerformanceAnalytics)#skew
library(moments) # carica il pacchetto per l'analisi statistica, kur
# Dobbiamo però tener conto del numero di 0 presenti: log(0) = -Inf, quindi
forest$area <- log(forest$area+1)
summary(forest$area)


```
come possiamo vedere la mediana e la media sono diminuite.
```{r, echo=F, message=F,warning=F}
skew_xts <-  skewness(forest$area)#skewness
#skew_xts

dev_standard=sqrt(var(forest$area))#dev standard
#dev_standard

kur=kurtosis(forest$area) # coefficiente di curtosi

x <- (c(skew_xts))
# una variabile ordinale
y <- (c(dev_standard))

# una variabile cardinale (integer)
z <- c(kur)
mydata <- data.frame(skewness=x, deviazione=y, curtosi=z) 
mydata
```

Possiamo vedere l'indice di asimmetria(skewness), l'indice di dispersione(curtosi) e la deviazione standard.

```{r,figures-side16, echo=F, message=F,warning=F}
library(tseries)#J-B test
jarque.bera.test(forest$area)# J-B test
```

Si tratta di un test di normalità che verifica, come ipotesi nulla, simultaneamente se l’asimmetria(skewness) e la curtosi sono coerenti con i valori che dovrebbero assumere sotto l’ipotesi nulla di normalità, ossia rispettivamente 0 e 3. Sotto l’ipotesi nulla H0 il test si distribuisce asintoticamente come una chi-quadro con 2 gradi di libertà. Tale ipotesi viene rifiutata per valori di JB troppo grandi.

Il Jarque Bera Test indica che la statistica del test è 145.49, con un valore p di 2.2e-16. Rifiuteremo, per quando detto in precedenza, l'ipotesi nulla che i dati siano distribuiti normalmente in questa circostanza.


\newpage

## Boxplot

```{r, figures-side4, fig.show="hold", out.width="50%", echo=F, message=F,warning=F}
# Correlazione tra variabili (quantitative):
# OPZIONALE (non dà punti extra):
# Siccome i mesi e giorni sono variabili qualitative con più livelli, R automaticamente splitta in livelli le variabili usando il modello lineare o lineare generalizzato.
# Proviamo a farlo noi con una funzione implementata in R:
# forest <- fastDummies::dummy_cols(forest, remove_first_dummy = TRUE)[-c(1,2)]
# summary(forest)
# Visualizzazione delle variabili:
boxplot(forest[,-c(1,2)], main="variables", col=rainbow(9), line = "box")
mtext("Fig.1", side=4, line=1)
# c'è differenza nei giorni?
boxplot(forest$area ~ Days, xlab = "day", ylab = "area", main="week", col=rainbow(7))
mtext("Fig.2", side=4, line=1)
# cosa succede a Dicembre?
boxplot(forest$area ~ Months, xlab = "mounth", ylab = "area", main="year", col=rainbow(12))
mtext("Fig.3", side=4, line=1)

library(corrplot)
M <- cor(as.matrix(forest[,-c(1,2)])) # correlation matrix
corrplot(M, method = 'number')
mtext("Fig.4", side=4, line=1)#side  1 = sotto, 2 = sinistra, 3 = sopra, 4 = destra.
#line da 1,-1,-2 ecc si sposta verso il centro
```
-Come possiamo vedere da questo correlation plot(fig.4) le variabili che sono correlate positivamente di più
sono: DC con DMC, ISI e FFMC, temp e DC. Le variabili correlate negativamente di più sono, invece: RH e temp.
Concentrandoci sulla variabile risposta (area) non ci sono correlazioni forti con nessuna delle covariate.

-Dal box plot delle variabili(fig.1) possiamo determinare che le mediane di quasi tutte le variabili sono più o meno simili quindi ci sono poche differenze, inoltre possiamo notare come in tutte le variabili ci siano degli outliers sia al minimo che al massimo. La covariata DMC, invece, presenta dei baffi più lunghi il che implica che tale variabile ha valori più incoerenti rispetto alle altre, la mediana è lontana da tutte le altre ed è spostata molto verso il terzo quartile. La covariata DC ha valori molto piu elevati rispetto alle altre covariate, percio non terremo conto di questa covariata.

-Dal box plot dei giorni della settimana(fig.2) possiamo vedere come le mediane siano simili tra di loro, come anche i baffi, questo dimostra come i giorni della settimana abbiano tutti valori coerenti tra di loro.

-Dal box plot dei mesi dell'anno(fig.3) notiamo come il mese di dicembre e quello di maggio siano quelli più incoerenti rispetto agli altri mesi. Il mese di agosto presenta molti più outliers rispetto agli altri mesi.


# Domande specifiche

Avvalendoci di questo dataset, siamo interessati a modellare l'area bruciata della foresta in funzione delle altre variabili. In particoalare, siamo interessati a capire nel mese di agosto come possiamo spiegare l'area bruciata, vogliamo capire anche come si comportano i vari modelli(semplice, polinomiale e interazioni tra covariate) e interpretare i loro risultati. Nello specifico vogliamo scoprire da quali variabili dipende maggiormente l'area bruciata e anche vedere come si comporta il modello in previsione. 

# Metodologia

I metodi usati per raggiungere gli obiettivi sono dei metodi di regressione lineare, ci permettono di spiegare una variabile risposta (Y=area bruciata) in funzione delle altre variabili esplicative a disposizione nel dataset(covariate, X). Seguiremo i seguenti step:

-Step1. Dato che non sarebbe sufficientemente esaustivo usare solo una porzione dei dati, verranno utilizzati tutti i dati a nostra disposizione. Alleneremo quindi 3 modelli di diversi di complessità.

-Step2. Rimuoveremo gli outliers per vedere come cambiano gli R2, cosi facendo scegliamo il miglior modello in base a chi ha l'RMSE piu basso.

-Step3. Utilizzeremo la regressione Lasso che ci permette di penalizzare alcuni regressori, questo per rendere il modello piu semplice(facciamo model selection), successivamente useremo la k-fold cross-validation per trovare un valore di lambda ottimale, la cross-validation è un ottimo modo per non overfittare e trovare il miglior modello.

# Analisi dati e discussione risultati

Prendiamo in considerazione solamente il mese di agosto per poter spiegare come varia l'area bruciata in relazione alle altre variabili.
Questa fase sarà svolta su tutti i campioni a nostra disposizione(non ha senso prendere il 70% dei campioni per via del basso numero di dati).

```{r, echo=F, message=F}
#summary(forest)

forest_subset <- forest[which(forest$month=="aug"),]
#summary(forest_subset)
forest_subset <- forest_subset[,-c(1:2)]#elimino colonne month,day e rain(visto che rain = 0) dal dataset 
#forest_subset
```

Proviamo a fare un modello lineare con i dati del mese di agosto. Le variabili che secondo noi ha piu senso considerare nel modello sono: rain ,RH ,temp, FFMC, e DMC. RH-FFMC-DMC sono degli indici che tengono conto dell'umidità. Nessuno di questi parametri agisce in modo diretto sullo sviluppo dell’incendio, ma sono tutti fattori predisponenti, perciò consideriamo rilevante studiare come influenzano l'area incendiata. Per capire la correlazione lineare tra la variabile risposta e le covariate mostriamo alcuni scatterplot.

```{r, figures-side8, fig.show="hold", out.width="50%",echo=F, message=F, warning=F}
#+(temp*DMC) potrebbe essere utile
# scatterplot per capire che relazione c'e tra l'area bruciata e le varie covariate(spoiler i nostri dati non seguono nessuna regola)
library(ggplot2)
library(hrbrthemes)
area=forest_subset$area
temp=forest_subset$temp
ggplot(forest_subset, aes(x=area, y=temp)) +
geom_point() +
geom_smooth(method=lm , color="red", se=FALSE)

area=forest_subset$area
ISI=forest_subset$ISI
ggplot(forest_subset, aes(x=area, y=ISI)) +
geom_point() +
geom_smooth(method=lm , color="red", se=FALSE)

area=forest_subset$area
FFMC=forest_subset$FFMC
ggplot(forest_subset, aes(x=area, y=FFMC)) +
geom_point() +
geom_smooth(method=lm , color="red", se=FALSE)

area=forest_subset$area
wind=forest_subset$wind
ggplot(forest_subset, aes(x=area, y=wind)) +
geom_point() +
geom_smooth(method=lm , color="red", se=FALSE)
 
```
Come possiamo vedere le correlazioni non sono molto significative, l'R2 tende a 0 quindi c'è una forte mancanza di correlazione che ci suggerisce di usare il modello vuoto per i nostri test. Visto il gran numero di zeri deicidiamo di togliere la maggioraparte di essi per vedere come performano i modelli. Proviamo ora a creare 3 modelli(semplice, polinomiale e polinomiale con interazioni).
```{r,echo=F, message=F}
# Optional:
#forest <- fastDummies::dummy_cols(forest, remove_first_dummy = TRUE)[-c(1,2)]
#Regole classiche sono 70% training e 30% test (o 80-20 a vostra scelta)
set.seed(125) # il seme serve per riprodurre le analisi (reproducibilità del codice)
#sample <- sample(c(TRUE, FALSE), nrow(forest_subset ), replace=TRUE, prob=c(0.7,0.3))
#train  <- forest_subset [sample, ]
#test   <- forest_subset [!sample, ]

# Modello con una sola variabile:
# model = lm(area ~ rain, data = train)

#summary(model)
# Modello con poche::40,42,51,52,57,58,66,68:73,92:94,77,79,80,82,85,87,89,97:100,104,105,107,113:116,119,123:125,129:131,134,138

rownames(forest_subset)<-NULL

forest_subset = forest_subset[-c(1:39,70,75,82,85,94,95,100:102,110,112:117,122,124,125,127,130,132,134,137:139,142:145,149,150,152,158:161,164,169:171,175,176,177,180,184),]


model1 = lm(area ~ DMC+ISI, data = forest_subset)
summary(model1)
# modello polinomiale: posssiamo vedere dai risutati come i p value si siano alzati come anche l'r2 si è alzato
#model2 = lm(area ~ temp+DMC+FFMC+I(temp^2)+I(DMC^2)+I(rain^2)+I(FFMC^2), data = forest_subset)
#summary(model2)
model2 = lm(area ~  I(temp^2)+I(temp^3)+wind+I(wind^2), data = forest_subset)
summary(model2)

model3 = lm(area ~ temp+I(temp^3)+wind+RH+I(RH^2)+I(RH*wind)+I(temp^2*wind^2)+I(RH*temp), data = forest_subset)
summary(model3)


```

Come possiamo vedere i nostri modelli non performano benissimo, con degli R2 (2%,7.7%,7.8%) così bassi i modelli hanno un elevato margine di errore. Il modello 1 ci suggerisce che il modello migliore è quello senza nessuna covariata e quindi avrebbe senso tenere soltanto l'intercetta. Il modello 2 ci evidenzia come i termini polinomiali rendano la correlazione tra area e le covariate un pò più significativa (rispetto al modello 1). 
Il modello 3 ha un R2 simile al modello 2, ma le sue covariate non sono significative. Togliamo dal primo modello le covariate con i p-value piu grandi(ISI). Proviamo a vedere se ci sono degli Outliers(valori estremi) nei modelli.

```{r,echo=F, message=F}
#rownames(forest_subset)
#summary(forest_subset)

rownames(forest_subset)<-NULL

#rownames(forest_subset)
#forest_subset

#rownames(forest)
#rownames(train)
#rownames(test)
#forest = forest[-c(3),]
#rownames(forest)

```

```{r,figures-side5, fig.show="hold", out.width="50%", echo=F, message=F, warning=F}
# Diagnostic plot del modello:
par(mfrow=c(2,2)) # finestra grafica 2x2
plot(model3)
par(mfrow=c(1,1)) # riportiamo ai valori di default

mtext("Fig.1", side=4, line=1)#side  1 = sotto, 2 = sinistra, 3 = sopra, 4 = destra.

# Rimuovere osservazioni basandoci sui valori delle variabili:
# train=train[!(train$temp>300),]
# rimuovere outlier:
# install.packages("olsrr")
library(olsrr)
ols_plot_resid_lev(model3)

#mtext("Fig.2", side=4, line=1)#side  1 = sotto, 2 = sinistra, 3 = sopra, 4 = destra.
```

Possiamo vedere come nei grafici (Fig.1), un numero considerevole di osservazioni non segue l'andamento desiderato, poniamo maggiore attenzione sul grafico Q-Q Res. dove possiamo vedere che i vari valori alle code tendono a spostarsi di molto, l'andamento non tende per niente alla normale. Per quanto riguarda il grafico a destra possiamo notare come alcune rilevazioni siano parecchio "lontane" rispetto alle altre, poniamo attenzione soprattuto a quelle che sono Outlier&Leverage e le rimuoviamo. 



```{r,echo=F, message=F}
# Removing observations guardando numero dell'osservazione:
#rownames(train)#  per vedere il la posizione dei valori di train
#train = train[-c(76,78,47,3,114,45,24,26,120),]#attenzione i numeri si riferiscono alla posizione dell'array degli outlier25,91,34,76,63,55

forest_subset = forest_subset[-c(25,91,34,76,63,55),]
#con tutto database dato
#416 421 228 13 500 212 model 1 e 6
#118,121 ,66 ,4 ,168, 64

#120,122,510
#36,38,178

#236,64,182,183,148,118
#68,15,

#solo train
#416 421 228 13 500 212 model 1 e 6
#76,78 ,47 ,3 ,114, 45

#120,122,510
#24,26,120


  
# Modello 1 senza outlier:rain+RH+temp+DMC
#model1 = lm(area ~rain+RH+temp+DMC, data = train)
#summary(model1)
# modello con tutte le variabili:
#model2 = lm(area ~ area ~ temp+I(temp^2)+I(temp^3)+wind+I(wind^2)+RH+I(RH^2), data = train)
#summary(model2)

# modello con le interazioni:
#model3 = lm(area ~ temp+I(temp^2)+I(temp^3)+wind+I(wind^2)+RH+I(RH^2)+I(temp*wind)+I(RH*wind)+I(RH*temp), data = train)
#summary(model3)





#tutti dati

# Modello 1 senza outlier:rain+RH+temp+DMC
model1 = lm(area ~ DMC, data = forest_subset)
summary(model1)
# modello con tutte le variabili:
model2 = lm(area ~ I(temp^2)+I(temp^3)+wind+I(wind^2), data = forest_subset)
summary(model2)

# modello con le interazioni:
model3 = lm(area ~ temp+I(temp^3)+wind+RH+I(RH^2)+I(RH*wind)+I(temp^2*wind^2)+I(RH*temp)+I(temp*ISI), data = forest_subset)
summary(model3)


#rownames(forest_subset)



# Test ANOVA
#anova(model3)

```

I modelli presentano un leggero miglioramento. Il modello 1 peggiora e quindi ci dice in definitiva che un modello lineare semplice non conviene per studiare questo dataset. Il modello 2 migliora leggermente, un r^2 cosi piccolo e un r^2 corretto cosi diverso ci indica che ciò è dovuto al fatto che il secondo corregge il primo tenendo conto anche di n(numero campioni) e di p(prametri). Se n non è molto più grande di p, allora l'R2 corretto penalizza R^2 poiché c'è il forte rischio di andare in over-fitting. Il modello 3 si è rilevato essere il migior modello tra i 3, con un r^2 di 0.19(comunque basso) e le covariate che diventano un minimo significative, è il modello che si adatta meglio ai nostri dati.

## Scelta modello

Per valutare quale dei 3 modelli sia meglio abbiamo analizzato in precedenza i diversi r^2 per capire chi avesse un RMSE piu piccolo(modello 3). Vogliamo mettere i 3 modelli a confronto anche tramite la tecnica AIC(Akaike information criterion). Consiste in un metodo per la valutazione e il confronto tra modelli statistici. Fornisce una misura della qualità della stima di un modello statistico tenendo conto sia della bontà di adattamento che della complessità del modello. La regola è quella di preferire i modelli con l’AIC più basso. 

```{r, echo=F,message = F,warning=F}
# Create vector with values
a = c(AIC(model1), BIC(model1),AIC(model2), BIC(model2),AIC(model3), BIC(model3))

# Akaike Information Criterion (AIC) estimates the in-sample prediction error and indicates the relative quality of statistical models for a given dataset (it is only useful to compare models based on the same data). Bayesian Information Criterion (BIC) is a penalized-likelihood criterion derived from Bayesian probability. It is closely related to AIC. Generally, lower values of BIC and AIC are preferred.

# Create vector with nforest
b = c("AIC lm 1", "BIC lm 1", "AIC lm 2", "BIC lm 2","AIC lm 3", "BIC lm 3")

# Link the values with nforest
names(a) = b
print(a)
```
I risultati ci mostrano come il modello 3 abbia l'AIC piu basso nonostante sia molto piu complesso rispetto al primo e al secondo modello, questo significa che il primo e il secondo modello performano molto male. Scegliamo(tramite r^2) il 3 modello per svolgere le previsioni.

## Previsioni puntuale

Per stima puntuale s’intende l’insieme dei metodi inferenziali che permettono di attribuire un valore ad un parametro della popolazione, utilizzando i dati di un campione casuale osservato (x1, x2,…,xn) ed elaborandoli. Per valutare la bontà di uno stimatore è necessario considerare le stime ottenute ripetendo un grande numero di volte il processo impiegato per eseguire una stima.  

```{r,echo=F, message = F}
#use lasso regression model to predict response value
new = forest_subset
previsioni_mod2 = predict(model3, newdata = new)#previsione puntuale

#find SST and SSE
sst <- sum((forest_subset$area - mean(forest_subset$area))^2)
sse <- sum((previsioni_mod2 - forest_subset$area)^2)

# Root Mean Squared Error: è una misura dell'errore che compiamo
sqrt(mean((forest_subset$area - previsioni_mod2)^2))#--
```

## LASSO regression

La tecnica LASSO(least absolute shrinkage and selection operator) è un metodo di analisi della regressione che esegue sia la selezione delle variabili sia la regolarizzazione per migliorare l'accuratezza della previsione e l'interpretabilità del modello statistico risultante. Il metodo lasso presuppone che i coefficienti del modello lineare siano sparsi, ossia che pochi di essi siano non nulli. 

```{r,figures-side7, fig.show="hold", out.width="50%", echo=F, message = F, warning=F}
#penalizza le covariate,avra una parte classica piu un errore

# install.packages("glmnet") # se non è già stato installato
library(glmnet) 

#define response variable
y <- forest_subset$area

#define matrix of predictor variables 
x <- model.matrix(area ~ temp+I(temp^3)+wind+RH+I(RH^2)+I(RH*wind)+I(temp^2*wind^2)+I(RH*temp)+I(temp*ISI),data=forest_subset)

#x <- data.matrix(train[,c("temp","DMC","FFMC")])

#perform k-fold cross-validation to find optimal lambda value, la cross-validation è un ottimo modo per non overfittare e trovare il miglior modello
cv_model <- cv.glmnet(x, y, alpha = 1)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
#best_lambda#miglior lambda per penalizzare

#produce plot of test MSE by lambda value
plot(cv_model) 

# Fittiamo il modello con il best lambda (penalizzazione)

best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
#coef(best_model)
```

Il grafico dovrebbe assomigliare ad una curva esponenziale, nel nostro caso il mean-squared error tende ad un andamento esponenziale 2 volte, ma alla fine torna al punto di partenza. Questo sta ad indicare che indipendentemente dal lambda non cambia la penalizzazione, dovuto al fatto che i regressori non hanno molto senso.

## Previsioni con Lasso
```{r, message = F, warning=F}
#use lasso regression model to predict response value
new = model.matrix(area ~ temp+I(temp^3)+wind+RH+I(RH^2)+I(RH*wind)+I(temp^2*wind^2)
                   +I(RH*temp)+I(temp*ISI),data=forest_subset)
previsioni = predict(best_model, s = best_lambda, newx = new)

# Root Mean Squared Error (RMSE): è una misura dell'errore che compiamo
sqrt(mean((forest_subset$area - previsioni)^2))#errore minimo

```

Come possiamo vedere la previsione con la Lasso è poco peggiore rispetto alla previsone puntuale, decidiamo quindi di usare la previsione puntuale per prevedere i dati. 

# Conclusioni

Concentrandosi sul mese di agosto, spiegare l'area bruciata in funzionde delle altre variabili risulta non facile visto la poca quantità di dati a disposizione. Poiché il valore R^2 del modello è molto basso, probabilmente i predittori avranno un errore significativo e potrebbero non essere affidabili. Gli sviluppi futuri potttrebbero essere:

-Avere piu dati e/o aggiungere qualche altra variabile (e.g. variabili spaziali) per una maggior accuratezza nei risultati.

-Si potrebbero implementare delle reti neurali per analizzare i dati.

-Si potrebbero utilizzare altre tecniche come la SVM o la random forest(non overfitta, è molto accurata ed parecchio complessa). [^b]

\newpage

[^b]: Abbiamo consultato diverse fonti per realizzare questo report:
Per il layout- <https://bookdown.org/yihui/rmarkdown/>.
Per confrontare i risultati- <https://rstudio-pubs-static.s3.amazonaws.com/419751_b251adb1ab8e40f7aeab8b5c4a739c4f.html>.
Per risolvere problemi di natura tecnica- <https://stackoverflow.com/>